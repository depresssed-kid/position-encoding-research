{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6397f39-4822-4496-be7d-71b853147b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Swinv2Config, Swinv2Model\n",
    "from transformers import AutoModel\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    AutoModelForImageClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from datasets import load_dataset, ClassLabel\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import math\n",
    "import cv2\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch import einsum\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as Data\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "import time\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b399c82f-5d35-405a-847d-8940a75b8223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Swinv2ForImageClassification were not initialized from the model checkpoint at microsoft/swinv2-tiny-patch4-window8-256 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 5  \n",
    "model_name = \"microsoft/swinv2-tiny-patch4-window8-256\"\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_classes,\n",
    "    id2label={i: str(i) for i in range(num_classes)},\n",
    "    label2id={str(i): i for i in range(num_classes)},\n",
    "    ignore_mismatched_sizes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6c38f15e-b1b1-42dc-835a-6744d17a7153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в случае с обычным MLP пропускается\n",
    "kernel_size = 3\n",
    "window_size = 2* model.swinv2.config.window_size -1\n",
    "conv_pos_1 = nn.Conv1d(2, 512, kernel_size, padding='same')\n",
    "for stage in model.swinv2.encoder.layers:\n",
    "    for block in stage.blocks:\n",
    "        out = block.attention.self.continuous_position_bias_mlp[2].out_features\n",
    "        conv_pos_2 = nn.Conv1d(512, out, kernel_size, padding='same')\n",
    "        block.attention.self.continuous_position_bias_mlp = nn.Sequential(Rearrange('b h w c -> b c (h w)'),\n",
    "                                                                            conv_pos_1,\n",
    "                                                                            nn.ReLU(),\n",
    "                                                                            conv_pos_2,\n",
    "                                                                            Rearrange('b c (h w) -> b h w c', h=window_size, w=window_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8cee2fc9-f733-4091-bb79-94a30addfbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для случайной инициализации весов (для более честного сравнения с conv1d), пропускается если используется свертка\n",
    "pos_1 = nn.Linear(2, 512)\n",
    "for stage in model.swinv2.encoder.layers:\n",
    "    for block in stage.blocks:\n",
    "        out = block.attention.self.continuous_position_bias_mlp[2].out_features\n",
    "        pos_2 = nn.Linear(512, out)\n",
    "        block.attention.self.continuous_position_bias_mlp = nn.Sequential(pos_1,\n",
    "                                                                          nn.ReLU(),\n",
    "                                                                          pos_2,\n",
    "                                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a2ae3623-9000-4a05-8df1-e0ac6d2130f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for stage in model.swinv2.encoder.layers:\n",
    "    for block in stage.blocks:\n",
    "        for param in block.attention.self.continuous_position_bias_mlp.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "104faa31-c948-48d0-87a3-8ef47710e189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes:  ['Daphne', 'Fred', 'Scooby', 'Shaggy', 'Velma']\n"
     ]
    }
   ],
   "source": [
    "data_path = 'D:\\\\air_qual\\\\dataset'\n",
    "for dirname, _, filenames in os.walk(data_path):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)\n",
    "        \n",
    "class_names = sorted(os.listdir(data_path))\n",
    "num_classes = len(class_names)\n",
    "\n",
    "img_size = (224, 224, 3)\n",
    "\n",
    "print('classes: ', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "43fc0cbf-9e5f-4a4f-9dc0-a43fdfd299e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images:\n",
      "\n",
      "Daphne -> done\n",
      "Fred -> done\n",
      "Scooby -> done\n",
      "Shaggy -> done\n",
      "Velma -> done\n",
      "\n",
      "\n",
      "labels shape: (221, 5)\n",
      "images shape: (221, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "images = []\n",
    "\n",
    "print('images:\\n')\n",
    "for cl in class_names:\n",
    "    print(cl, end=' -> ')\n",
    "    for img in os.listdir(data_path +'/'+ cl):\n",
    "        label = np.zeros(num_classes)\n",
    "        label[class_names.index(cl)] = 1\n",
    "        labels.append(label)\n",
    "        image = cv2.imread(data_path + \"/\" + cl + '/' + img, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image,(224,224))[:, :, ::-1]\n",
    "        image = np.asarray(image)\n",
    "        images.append(image)\n",
    "    print('done')\n",
    "\n",
    "\n",
    "labels = np.asarray(labels)\n",
    "images = np.asarray(images)\n",
    "\n",
    "print(f'\\n\\nlabels shape: {labels.shape}')\n",
    "print(f'images shape: {images.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4539c23c-e6ba-4ee6-822a-b296aec58b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet():\n",
    "  def __init__(self,images,labels,transform = None):\n",
    "    self.image = images\n",
    "    self.label = labels\n",
    "    self.transform = transform\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      image = self.image[index]\n",
    "      if self.transform:\n",
    "          image = self.transform(self.image[index])\n",
    "      return image, self.label[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "de8bb43c-eb52-4842-921b-41f727de7523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data mean [0.48534315 0.4474048  0.40226592]\n",
      "Data std [0.35551016 0.32614718 0.33380135]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "y_val = torch.from_numpy(y_val).long()\n",
    "\n",
    "if len(y_train.shape) > 1 and y_train.shape[1] > 1:\n",
    "    y_train = torch.argmax(y_train, dim=1)\n",
    "if len(y_val.shape) > 1 and y_val.shape[1] > 1:\n",
    "    y_val = torch.argmax(y_val, dim=1)\n",
    "\n",
    "\n",
    "DATA_MEANS = (X_train / 255.0).mean(axis=(0, 1, 2))\n",
    "DATA_STD = (X_train / 255.0).std(axis=(0, 1, 2))\n",
    "print(\"Data mean\", DATA_MEANS)\n",
    "print(\"Data std\", DATA_STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "07b4f734-2470-4c43-abb6-44b1d9bfd580",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=DATA_MEANS, std=DATA_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6206f3ec-882c-4e75-beb4-994efc1e7cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "dataset_train = DataSet(X_train, y_train,transform)\n",
    "dataset_test = DataSet(X_val, y_val,transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=0)#num_workers=0 важно из-за проблем с многопоточностью в windows\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b207c2b0-1409-449b-851d-3695e79057d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 12\n",
    "learning_rate = 0.0003\n",
    "num_classes = 5\n",
    "patience = 12 # количество эпох которые loss может не уменьшаться перед остановкой обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d37eabeb-9b22-4242-8eb0-e49de9e8c6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Test Accuracy: 0.060751748251748255, train acc: 0.22727272727272727 \n",
      "test loss: 1.5578160285949707, train loss: 1.6206666231155396\n",
      "Epoch [2/100], Test Accuracy: 0.06512237762237762, train acc: 0.2840909090909091 \n",
      "test loss: 1.5189154148101807, train loss: 1.5589484734968706\n",
      "Epoch [3/100], Test Accuracy: 0.0777972027972028, train acc: 0.3068181818181818 \n",
      "test loss: 1.5383647680282593, train loss: 1.5245891484347256\n",
      "Epoch [4/100], Test Accuracy: 0.09746503496503496, train acc: 0.42613636363636365 \n",
      "test loss: 1.470696210861206, train loss: 1.4768278923901645\n",
      "Epoch [5/100], Test Accuracy: 0.09877622377622379, train acc: 0.5227272727272727 \n",
      "test loss: 1.43265962600708, train loss: 1.4162266471169211\n",
      "Epoch [6/100], Test Accuracy: 0.10751748251748251, train acc: 0.5511363636363636 \n",
      "test loss: 1.235213279724121, train loss: 1.353129354390231\n",
      "Epoch [7/100], Test Accuracy: 0.11145104895104894, train acc: 0.5511363636363636 \n",
      "test loss: 1.192201852798462, train loss: 1.2927166115153919\n",
      "Epoch [8/100], Test Accuracy: 0.1284965034965035, train acc: 0.625 \n",
      "test loss: 1.183074951171875, train loss: 1.1820482990958474\n",
      "Epoch [9/100], Test Accuracy: 0.12150349650349651, train acc: 0.6306818181818182 \n",
      "test loss: 1.0695630311965942, train loss: 1.0954999381845647\n",
      "Epoch [10/100], Test Accuracy: 0.166520979020979, train acc: 0.6363636363636364 \n",
      "test loss: 0.8666539788246155, train loss: 1.0236775983463635\n",
      "Epoch [11/100], Test Accuracy: 0.15122377622377622, train acc: 0.75 \n",
      "test loss: 0.6691372990608215, train loss: 0.8919589790430936\n",
      "Epoch [12/100], Test Accuracy: 0.14685314685314685, train acc: 0.8011363636363636 \n",
      "test loss: 0.7776824235916138, train loss: 0.7899918556213379\n",
      "Epoch [13/100], Test Accuracy: 0.1569055944055944, train acc: 0.8011363636363636 \n",
      "test loss: 0.5989664196968079, train loss: 0.7624548294327476\n",
      "Epoch [14/100], Test Accuracy: 0.19055944055944057, train acc: 0.8011363636363636 \n",
      "test loss: 0.6387573480606079, train loss: 0.6848161003806374\n",
      "Epoch [15/100], Test Accuracy: 0.15384615384615385, train acc: 0.8295454545454546 \n",
      "test loss: 0.5695978403091431, train loss: 0.6668948314406655\n",
      "Epoch [16/100], Test Accuracy: 0.15821678321678323, train acc: 0.8465909090909091 \n",
      "test loss: 0.6681823134422302, train loss: 0.6434706991369074\n",
      "Epoch [17/100], Test Accuracy: 0.13986013986013984, train acc: 0.8522727272727273 \n",
      "test loss: 0.5486792922019958, train loss: 0.5623144724152305\n",
      "Epoch [18/100], Test Accuracy: 0.16083916083916083, train acc: 0.8522727272727273 \n",
      "test loss: 0.35117626190185547, train loss: 0.5710427408868616\n",
      "Epoch [19/100], Test Accuracy: 0.17526223776223776, train acc: 0.9034090909090909 \n",
      "test loss: 0.4821970760822296, train loss: 0.48765658790414984\n",
      "Epoch [20/100], Test Accuracy: 0.1848776223776224, train acc: 0.875 \n",
      "test loss: 0.6625188589096069, train loss: 0.5118322995575991\n",
      "Epoch [21/100], Test Accuracy: 0.17657342657342656, train acc: 0.9204545454545454 \n",
      "test loss: 0.5453742742538452, train loss: 0.4455893337726593\n",
      "Epoch [22/100], Test Accuracy: 0.17526223776223776, train acc: 0.9261363636363636 \n",
      "test loss: 0.3789810836315155, train loss: 0.38873829624869605\n",
      "Epoch [23/100], Test Accuracy: 0.18924825174825174, train acc: 0.9204545454545454 \n",
      "test loss: 0.22672204673290253, train loss: 0.3994247547604821\n",
      "Epoch [24/100], Test Accuracy: 0.15952797202797203, train acc: 0.9375 \n",
      "test loss: 0.37656164169311523, train loss: 0.3721050728451122\n",
      "Epoch [25/100], Test Accuracy: 0.19055944055944057, train acc: 0.9375 \n",
      "test loss: 0.3837939500808716, train loss: 0.3630692674355073\n",
      "Epoch [26/100], Test Accuracy: 0.18356643356643357, train acc: 0.9375 \n",
      "test loss: 0.3816450834274292, train loss: 0.33054289628158917\n",
      "Epoch [27/100], Test Accuracy: 0.17657342657342656, train acc: 0.9431818181818182 \n",
      "test loss: 0.30839064717292786, train loss: 0.3118622330102054\n",
      "Epoch [28/100], Test Accuracy: 0.1778846153846154, train acc: 0.9545454545454546 \n",
      "test loss: 0.28866541385650635, train loss: 0.32603233510797675\n",
      "Epoch [29/100], Test Accuracy: 0.1778846153846154, train acc: 0.9261363636363636 \n",
      "test loss: 0.28916677832603455, train loss: 0.2940489947795868\n",
      "Epoch [30/100], Test Accuracy: 0.1652097902097902, train acc: 0.9261363636363636 \n",
      "test loss: 0.36231470108032227, train loss: 0.3022923679514365\n",
      "Epoch [31/100], Test Accuracy: 0.17657342657342656, train acc: 0.9829545454545454 \n",
      "test loss: 0.16910454630851746, train loss: 0.23122669079086997\n",
      "Epoch [32/100], Test Accuracy: 0.18225524475524477, train acc: 0.9545454545454546 \n",
      "test loss: 0.31770530343055725, train loss: 0.2809357128360055\n",
      "Epoch [33/100], Test Accuracy: 0.1652097902097902, train acc: 0.9602272727272727 \n",
      "test loss: 0.10407374054193497, train loss: 0.24848473139784552\n",
      "Epoch [34/100], Test Accuracy: 0.17657342657342656, train acc: 0.9602272727272727 \n",
      "test loss: 0.19814257323741913, train loss: 0.25766507062045013\n",
      "Epoch [35/100], Test Accuracy: 0.1791958041958042, train acc: 0.9659090909090909 \n",
      "test loss: 0.1945723444223404, train loss: 0.20256660065867685\n",
      "Epoch [36/100], Test Accuracy: 0.1848776223776224, train acc: 0.9545454545454546 \n",
      "test loss: 0.23791468143463135, train loss: 0.24363025481050665\n",
      "Epoch [37/100], Test Accuracy: 0.17089160839160839, train acc: 0.9602272727272727 \n",
      "test loss: 0.22977717220783234, train loss: 0.2297508486292579\n",
      "Epoch [38/100], Test Accuracy: 0.1652097902097902, train acc: 0.9545454545454546 \n",
      "test loss: 0.13772207498550415, train loss: 0.20283981006253848\n",
      "Epoch [39/100], Test Accuracy: 0.18356643356643357, train acc: 0.9715909090909091 \n",
      "test loss: 0.2186211198568344, train loss: 0.18855339695106854\n",
      "Epoch [40/100], Test Accuracy: 0.18924825174825174, train acc: 0.9829545454545454 \n",
      "test loss: 0.20945081114768982, train loss: 0.154430476101962\n",
      "Epoch [41/100], Test Accuracy: 0.19361888111888115, train acc: 0.9602272727272727 \n",
      "test loss: 0.10827361792325974, train loss: 0.19854273511604828\n",
      "Epoch [42/100], Test Accuracy: 0.17657342657342656, train acc: 0.9602272727272727 \n",
      "test loss: 0.3671817481517792, train loss: 0.20999101142991672\n",
      "Epoch [43/100], Test Accuracy: 0.1848776223776224, train acc: 0.9829545454545454 \n",
      "test loss: 0.18096154928207397, train loss: 0.16479519619183106\n",
      "Epoch [44/100], Test Accuracy: 0.18924825174825174, train acc: 0.9772727272727273 \n",
      "test loss: 0.19741028547286987, train loss: 0.16053865714506668\n",
      "Epoch [45/100], Test Accuracy: 0.17089160839160839, train acc: 0.9715909090909091 \n",
      "test loss: 0.1860971450805664, train loss: 0.16923868723890997\n",
      "Epoch [46/100], Test Accuracy: 0.19055944055944057, train acc: 0.9715909090909091 \n",
      "test loss: 0.1321457028388977, train loss: 0.15284967151555148\n",
      "Epoch [47/100], Test Accuracy: 0.18225524475524477, train acc: 0.9829545454545454 \n",
      "test loss: 0.1270800083875656, train loss: 0.15392665497281335\n",
      "Epoch [48/100], Test Accuracy: 0.17089160839160839, train acc: 0.9659090909090909 \n",
      "test loss: 0.17872700095176697, train loss: 0.1718534305691719\n",
      "Epoch [49/100], Test Accuracy: 0.1778846153846154, train acc: 0.9829545454545454 \n",
      "test loss: 0.12197951972484589, train loss: 0.1244629794223742\n",
      "Epoch [50/100], Test Accuracy: 0.17089160839160839, train acc: 0.9772727272727273 \n",
      "test loss: 0.1454593539237976, train loss: 0.14467295834963972\n",
      "Epoch [51/100], Test Accuracy: 0.1722027972027972, train acc: 0.9829545454545454 \n",
      "test loss: 0.07764673978090286, train loss: 0.1370132484219291\n",
      "Epoch [52/100], Test Accuracy: 0.20192307692307693, train acc: 0.9829545454545454 \n",
      "test loss: 0.11539326608181, train loss: 0.10106101327321747\n",
      "Epoch [53/100], Test Accuracy: 0.1918706293706294, train acc: 0.9886363636363636 \n",
      "test loss: 0.10573164373636246, train loss: 0.1271002461964434\n",
      "Epoch [54/100], Test Accuracy: 0.1918706293706294, train acc: 0.9886363636363636 \n",
      "test loss: 0.15262481570243835, train loss: 0.13129333677616986\n",
      "Epoch [55/100], Test Accuracy: 0.17089160839160839, train acc: 0.9829545454545454 \n",
      "test loss: 0.10044150799512863, train loss: 0.11777106062932448\n",
      "Epoch [56/100], Test Accuracy: 0.17657342657342656, train acc: 0.9829545454545454 \n",
      "test loss: 0.13551516830921173, train loss: 0.12434066832065582\n",
      "Epoch [57/100], Test Accuracy: 0.18225524475524477, train acc: 0.9829545454545454 \n",
      "test loss: 0.11327720433473587, train loss: 0.09956039556048134\n",
      "Epoch [58/100], Test Accuracy: 0.19055944055944057, train acc: 0.9886363636363636 \n",
      "test loss: 0.04771799594163895, train loss: 0.10110278461467136\n",
      "Epoch [59/100], Test Accuracy: 0.16958041958041958, train acc: 0.9943181818181818 \n",
      "test loss: 0.09570595622062683, train loss: 0.09337521242824467\n",
      "Epoch [60/100], Test Accuracy: 0.1722027972027972, train acc: 0.9943181818181818 \n",
      "test loss: 0.12537434697151184, train loss: 0.08991014093837955\n",
      "Epoch [61/100], Test Accuracy: 0.19493006993006992, train acc: 0.9886363636363636 \n",
      "test loss: 0.105295330286026, train loss: 0.10254519500515678\n",
      "Epoch [62/100], Test Accuracy: 0.1848776223776224, train acc: 0.9943181818181818 \n",
      "test loss: 0.07883784174919128, train loss: 0.0784845118495551\n",
      "Epoch [63/100], Test Accuracy: 0.19493006993006992, train acc: 0.9886363636363636 \n",
      "test loss: 0.04841143637895584, train loss: 0.11114349114623936\n",
      "Epoch [64/100], Test Accuracy: 0.19930069930069932, train acc: 1.0 \n",
      "test loss: 0.037025947123765945, train loss: 0.0792870054190809\n",
      "Epoch [65/100], Test Accuracy: 0.18225524475524477, train acc: 0.9829545454545454 \n",
      "test loss: 0.04969072341918945, train loss: 0.11009282923557541\n",
      "Epoch [66/100], Test Accuracy: 0.19055944055944057, train acc: 0.9886363636363636 \n",
      "test loss: 0.08756951242685318, train loss: 0.08574710820208896\n",
      "Epoch [67/100], Test Accuracy: 0.18356643356643357, train acc: 0.9886363636363636 \n",
      "test loss: 0.06378927081823349, train loss: 0.08458725227551027\n",
      "Epoch [68/100], Test Accuracy: 0.17089160839160839, train acc: 1.0 \n",
      "test loss: 0.04587051644921303, train loss: 0.08493531579998406\n",
      "Epoch [69/100], Test Accuracy: 0.22027972027972031, train acc: 0.9943181818181818 \n",
      "test loss: 0.07836521416902542, train loss: 0.0753479427234693\n",
      "Epoch [70/100], Test Accuracy: 0.15952797202797203, train acc: 0.9886363636363636 \n",
      "test loss: 0.053316548466682434, train loss: 0.0718498362058943\n",
      "Epoch [71/100], Test Accuracy: 0.19055944055944057, train acc: 0.9829545454545454 \n",
      "test loss: 0.03855868801474571, train loss: 0.09564745358445427\n",
      "Epoch [72/100], Test Accuracy: 0.18924825174825174, train acc: 0.9772727272727273 \n",
      "test loss: 0.07947897911071777, train loss: 0.09977381066842513\n",
      "Epoch [73/100], Test Accuracy: 0.17089160839160839, train acc: 0.9829545454545454 \n",
      "test loss: 0.10666292160749435, train loss: 0.08637875470925462\n",
      "Epoch [74/100], Test Accuracy: 0.1778846153846154, train acc: 0.9886363636363636 \n",
      "test loss: 0.12352500855922699, train loss: 0.09072486446662383\n",
      "Epoch [75/100], Test Accuracy: 0.17089160839160839, train acc: 0.9829545454545454 \n",
      "test loss: 0.03608694672584534, train loss: 0.09867464446208694\n",
      "Epoch [76/100], Test Accuracy: 0.19055944055944057, train acc: 0.9829545454545454 \n",
      "test loss: 0.048984140157699585, train loss: 0.08044021000916307\n",
      "Epoch [77/100], Test Accuracy: 0.17657342657342656, train acc: 0.9943181818181818 \n",
      "test loss: 0.1410740613937378, train loss: 0.07484636371108619\n",
      "Epoch [78/100], Test Accuracy: 0.17657342657342656, train acc: 0.9943181818181818 \n",
      "test loss: 0.1163811907172203, train loss: 0.08107833462682637\n",
      "Epoch [79/100], Test Accuracy: 0.19055944055944057, train acc: 1.0 \n",
      "test loss: 0.047853946685791016, train loss: 0.06330515952272849\n",
      "Epoch [80/100], Test Accuracy: 0.17657342657342656, train acc: 0.9943181818181818 \n",
      "test loss: 0.2026364952325821, train loss: 0.06895795176652345\n",
      "Epoch [81/100], Test Accuracy: 0.17657342657342656, train acc: 1.0 \n",
      "test loss: 0.0726584643125534, train loss: 0.07267767021601851\n",
      "Epoch [82/100], Test Accuracy: 0.18356643356643357, train acc: 1.0 \n",
      "test loss: 0.04983174055814743, train loss: 0.07374120588329705\n",
      "Epoch [83/100], Test Accuracy: 0.19755244755244758, train acc: 0.9943181818181818 \n",
      "test loss: 0.05189516395330429, train loss: 0.05549309453503652\n",
      "Epoch [84/100], Test Accuracy: 0.18924825174825174, train acc: 0.9943181818181818 \n",
      "test loss: 0.11916971951723099, train loss: 0.060942712324586784\n",
      "Epoch [85/100], Test Accuracy: 0.19361888111888115, train acc: 1.0 \n",
      "test loss: 0.04102059453725815, train loss: 0.06517279656095938\n",
      "Epoch [86/100], Test Accuracy: 0.17657342657342656, train acc: 1.0 \n",
      "test loss: 0.05151256546378136, train loss: 0.04923418460583145\n",
      "Epoch [87/100], Test Accuracy: 0.19624125874125875, train acc: 1.0 \n",
      "test loss: 0.037030257284641266, train loss: 0.05364076335999099\n",
      "Epoch [88/100], Test Accuracy: 0.18356643356643357, train acc: 1.0 \n",
      "test loss: 0.0924469456076622, train loss: 0.056822459467432716\n",
      "Epoch [89/100], Test Accuracy: 0.18924825174825174, train acc: 0.9943181818181818 \n",
      "test loss: 0.017595773562788963, train loss: 0.05154117941856384\n",
      "Epoch [90/100], Test Accuracy: 0.18924825174825174, train acc: 0.9886363636363636 \n",
      "test loss: 0.07986485958099365, train loss: 0.07416419871151447\n",
      "Epoch [91/100], Test Accuracy: 0.1918706293706294, train acc: 0.9886363636363636 \n",
      "test loss: 0.11305080354213715, train loss: 0.07570425522598354\n",
      "Epoch [92/100], Test Accuracy: 0.19493006993006992, train acc: 0.9943181818181818 \n",
      "test loss: 0.061750348657369614, train loss: 0.06321404874324799\n",
      "Epoch [93/100], Test Accuracy: 0.19624125874125875, train acc: 0.9886363636363636 \n",
      "test loss: 0.03803550451993942, train loss: 0.05832215517081998\n",
      "Epoch [94/100], Test Accuracy: 0.18793706293706294, train acc: 0.9943181818181818 \n",
      "test loss: 0.030312322080135345, train loss: 0.05396781607785008\n",
      "Epoch [95/100], Test Accuracy: 0.1722027972027972, train acc: 0.9943181818181818 \n",
      "test loss: 0.027140406891703606, train loss: 0.04473713311282071\n",
      "Epoch [96/100], Test Accuracy: 0.19055944055944057, train acc: 1.0 \n",
      "test loss: 0.03087267093360424, train loss: 0.04515157250518149\n",
      "Epoch [97/100], Test Accuracy: 0.19624125874125875, train acc: 1.0 \n",
      "test loss: 0.025259749963879585, train loss: 0.035450847311453385\n",
      "Epoch [98/100], Test Accuracy: 0.1722027972027972, train acc: 0.9829545454545454 \n",
      "test loss: 0.025723889470100403, train loss: 0.06854522973299026\n",
      "Epoch [99/100], Test Accuracy: 0.19624125874125875, train acc: 0.9943181818181818 \n",
      "test loss: 0.01352005172520876, train loss: 0.050515994006259876\n",
      "Epoch [100/100], Test Accuracy: 0.19055944055944057, train acc: 0.9943181818181818 \n",
      "test loss: 0.056149039417505264, train loss: 0.05579433285377242\n",
      "время обучения: 6084.1148018836975\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min',patience=8)\n",
    "total_step = len(train_loader)\n",
    "total_step_test = len(test_loader)\n",
    "\n",
    "best_loss = float('inf')\n",
    "test_losses = []\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "train_accuracies = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_acc = 0\n",
    "    test_acc = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images).logits\n",
    "        loss = criterion(outputs , labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        ver, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        train_acc += accuracy_score(predicted.cpu().numpy(),labels.cpu().numpy())\n",
    "    final_train_acc = train_acc/total_step\n",
    "    train_accuracies.append(final_train_acc)\n",
    "    final_train_loss = running_loss / total_step\n",
    "\n",
    "    train_losses.append(final_train_loss)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        running_loss_test = 0\n",
    "        for (images, labels) in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images).logits \n",
    "            ver, predicted = torch.max(outputs, 1)\n",
    "            loss_test = criterion(outputs, labels)\n",
    "            running_loss_test += loss.item()\n",
    "            test_acc += accuracy_score(predicted.cpu().numpy(),labels.cpu().numpy())\n",
    "        final_test_acc = test_acc/total_step\n",
    "        val_loss = running_loss_test/total_step_test\n",
    "        scheduler.step(val_loss)\n",
    "        test_accuracies.append(final_test_acc)\n",
    "        test_losses.append(val_loss)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Test Accuracy: {final_test_acc}, train acc: {final_train_acc} ')\n",
    "        print(f\"test loss: {val_loss}, train loss: {final_train_loss}\")\n",
    "time_end = time.time()\n",
    "print(f\"время обучения: {time_end-time_start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b0c83b0f-8c8d-45a2-94b6-453e6779aba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22027972027972031"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6b3a5d-e8ad-4e10-909b-0ef315e7164d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
